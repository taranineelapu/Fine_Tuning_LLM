# Fine-Tuning Large Language Models Efficiently: A Case Study

-	To run the code file you need to install a few packages that are given in the code
-	This code file is self-sufficient, running each cell will give you the results
-	However, it is important to note that this code was written and specifically designed for systems with NVIDIA GPU and driver. Hence, if your system does not have an NVIDIA GPU this will throw a runtime error.
-	This code file uses the “Llama-2-7b-chat-hf" as the base model which is directly loaded from the hugging face
-	The dataset is also downloaded from Hugging Face - “guanaco-llama2-1k"
